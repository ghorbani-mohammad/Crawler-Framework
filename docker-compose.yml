version: '3.4'

services:
  crawler_db:
    container_name: crawler_db
    image: mdillon/postgis:11
    restart: unless-stopped
    volumes:
      - crawler_db:/var/lib/postgresql/data
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"

  crawler:
    image: crawler
    container_name: crawler_django
    command: ["python", "/app/manage.py", "runserver", "0.0.0.0:8200"]
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app
    ports: 
      - 8200:8200
    restart: unless-stopped
    environment:
      DEBUG: 'True'
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
  
  redis:
    image: redis
    container_name: crawler_redis
    volumes: 
      - /root/dbs/crawler/redis:/data
    restart: always
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
  
  celery_worker:
    image: crawler
    container_name: crawler_worker
    volumes:
      - .:/app
    command: ["celery", "-A", "app", "worker", "-l", "info", "--pidfile="]
    restart: always
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
  
  celery_scheduler:
    image: crawler
    container_name: crawler_beat
    volumes:
      - .:/app
    command: ["celery", "-A", "app", "beat", "-l", "info", "--pidfile="]
    restart: always
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
  
  chrome_browser:
    image: selenium/standalone-chrome
    container_name: crawler_chrome
    logging:
      driver: none
    restart: always
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"

volumes:
  crawler_db: